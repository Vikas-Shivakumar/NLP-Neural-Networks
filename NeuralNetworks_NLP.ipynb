{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "lVF4wbIzmMn8",
        "outputId": "f484fd97-17b8-4c3a-d0e9-3646ccf9ab3d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e72b5643-faf7-4bd6-a96f-273c206d4316\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e72b5643-faf7-4bd6-a96f-273c206d4316\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Data.csv to Data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('Data.csv')"
      ],
      "metadata": {
        "id": "qA-LSSL7nttb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[['Tweet','ADR_label']]"
      ],
      "metadata": {
        "id": "2EPJ8Axvn3MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data cleaning and preprocessing\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5_RZZflmsdx",
        "outputId": "c5e6b911-cd3a-4f1f-96af-5d15f51801a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(df)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', df['Tweet'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "WxoS8_-2nrS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-rLqLbwkoob1",
        "outputId": "1890be2c-908f-4577-9a51-bf8f9c9fcc17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Tweet  ADR_label\n",
              "0      Intravenous azithromycin-induced ototoxicity.          1\n",
              "1  Immobilization, while Paget's bone disease was...          1\n",
              "2  Unaccountable severe hypercalcemia in a patien...          1\n",
              "3  METHODS: We report two cases of pseudoporphyri...          1\n",
              "4  METHODS: We report two cases of pseudoporphyri...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef8277e5-99f5-4e1d-872a-e69061804919\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>ADR_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intravenous azithromycin-induced ototoxicity.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Immobilization, while Paget's bone disease was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Unaccountable severe hypercalcemia in a patien...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS: We report two cases of pseudoporphyri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS: We report two cases of pseudoporphyri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef8277e5-99f5-4e1d-872a-e69061804919')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef8277e5-99f5-4e1d-872a-e69061804919 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef8277e5-99f5-4e1d-872a-e69061804919');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ChGB8U51okB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Bag of Words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2500)\n",
        "X = cv.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "VzhIul0-ogS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the TFIDF model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tv = TfidfVectorizer(max_features=1500)\n",
        "X = tv.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "F3LlLDjLpula"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuruBXUWp81P",
        "outputId": "2db339c0-f563-41f0-b8f0-3180049238c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jfmb30NqBdv",
        "outputId": "cc34cf25-1d25-4c46-d9d1-693abe0976ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: gensim\n",
            "Version: 3.6.0\n",
            "Summary: Python framework for fast Vector Space Modelling\n",
            "Home-page: http://radimrehurek.com/gensim\n",
            "Author: Radim Rehurek\n",
            "Author-email: me@radimrehurek.com\n",
            "License: LGPLv2.1\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: numpy, six, smart-open, scipy\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word To Vec \n",
        "Pretrained"
      ],
      "metadata": {
        "id": "Oo6z0MlbqMJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byDgvewuqH43",
        "outputId": "a7cb629c-2be2-449c-9a3b-9e3595417b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "corpus = []\n",
        "for i in range(0, len(df)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', df['Tweet'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "from nltk import sent_tokenize\n",
        "from gensim.utils import simple_preprocess\n",
        "words=[]\n",
        "for sent in corpus:\n",
        "    sent_token=sent_tokenize(sent)\n",
        "    for sent in sent_token:\n",
        "        words.append(simple_preprocess(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ_oIXDpqnsC",
        "outputId": "2784d810-30fa-49a5-9490-177ae8bac8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word To Vec from Scratch"
      ],
      "metadata": {
        "id": "L-sSZj0Msu6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ1roPvsuXGs",
        "outputId": "5d54be38-4b3d-4fa5-b84f-a5b43be5f9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['intravenous', 'azithromycin', 'induced', 'ototoxicity']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Lets train Word2vec from scratch\n",
        "import gensim\n",
        "model=gensim.models.Word2Vec(words,window=5,min_count=2)"
      ],
      "metadata": {
        "id": "zNm9qQxMrfUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.corpus_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxIYXeTWsYk7",
        "outputId": "fb0045da-53e2-4d87-9b46-ed7982de752e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23516"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD4yH2ifsbQ6",
        "outputId": "0ce8cfb8-cc8d-4ec3-b11d-91115a0747c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4LJ_agiu5Pt",
        "outputId": "0bbc4683-5677-492a-bc0f-8f83609612f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f28fd616250>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_word2vec(doc):\n",
        "    # remove out-of-vocabulary words\n",
        "    #sent = [word for word in doc if word in model.wv.index_to_key]\n",
        "    #print(sent)\n",
        "    \n",
        "    return np.mean([model.wv[word] for word in doc if word in model.wv.index2word],axis=0)\n",
        "                #or [np.zeros(len(model.wv.index_to_key))], axis=0)\n",
        "        \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "hanM7WBpsebs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "LWV1gl6BshQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply for the entire sentences\n",
        "import numpy as np\n",
        "X=[]\n",
        "for i in tqdm(range(len(words))):\n",
        "    X.append(avg_word2vec(words[i]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5fOam1asmLq",
        "outputId": "86b81a17-2d54-4e80-d2c9-373621d3ba15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 8681/23516 [00:03<00:06, 2203.13it/s]/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "100%|██████████| 23516/23516 [00:15<00:00, 1476.55it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers:\n",
        "\n",
        "1. Use Pretrained model directly as a classifier\n",
        "2. Transformer model to extract embedding and use it as input to another classifier.\n",
        "3. Fine-tuning a Pretrained transformer model on custom config and dataset."
      ],
      "metadata": {
        "id": "vCydjgxxGVtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Build\n",
        "ANN\n",
        "RNN\n",
        "LSTM\n",
        "Bi-LSTM\n",
        "BERT\n",
        "GPT\n",
        "Roberta\n",
        "Albert\n",
        "Distilbert"
      ],
      "metadata": {
        "id": "X_PVToxkvmtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Network"
      ],
      "metadata": {
        "id": "dzuNRMTSGHvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oShX4IgbGHHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tudi1bJCx7Em",
        "outputId": "d4ad9416-01a1-44cc-f647-997a08d9bd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23516, 1500)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['ADR_label']"
      ],
      "metadata": {
        "id": "SW7EUUyGxZEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Divide the dataset into Train and Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
      ],
      "metadata": {
        "id": "Ln1iH_LjwzB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "y_train=tensorflow.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_test=tensorflow.keras.utils.to_categorical(y_test, num_classes=2)\n"
      ],
      "metadata": {
        "id": "a9PyQd8hwj6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=tensorflow.keras.utils.to_categorical(y, num_classes=2)"
      ],
      "metadata": {
        "id": "OK9y-x-dddui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "# X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "# X_val = np.array(X_val).reshape((X_val.shape[0], X_val.shape[1], 1))"
      ],
      "metadata": {
        "id": "iUjvJsdeSJ4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqAHNBBxc2GO",
        "outputId": "cb46d37a-8ea9-4830-9fc8-f55ab62088f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15755, 1500) (7761, 1500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import regularizers, optimizers"
      ],
      "metadata": {
        "id": "VGxbHIp6XZjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import regularizers, optimizers\n",
        "\n",
        "def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "    hidden_nodes = 512\n",
        "    output_nodes = 2\n",
        "        \n",
        "    model = Sequential()\n",
        "    model.add(Dense(hidden_nodes, input_shape=(2500,), activation='relu'))\n",
        "    model.add(Dense(hidden_nodes, activation='relu'))\n",
        "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
        "    \n",
        "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    \n",
        "    # Fit the model\n",
        "    model.fit(X_train, y_train, epochs=iterations, batch_size=32, verbose= 1)\n",
        "    score_train=model.evaluate(X_train,y_train)\n",
        "    score_val=model.evaluate(X_test,y_test)\n",
        "\n",
        "    return score_train, score_val"
      ],
      "metadata": {
        "id": "Dp47GjB5tCZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_test_loop1(iterations, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "    hidden_nodes = 256\n",
        "    output_nodes = 2\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(hidden_nodes, input_shape=(2500,), activation='relu'))\n",
        "    model.add(Dense(hidden_nodes, activation='relu'))\n",
        "    model.add(Dense(output_nodes, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
        "    \n",
        "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    \n",
        "    # Fit the model\n",
        "    model.fit(X_train_subset, y_train_subset, epochs=iterations, batch_size=32, verbose= 1)\n",
        "    #score = model.evaluate(X_test, y_test, verbose=0)\n",
        "    \n",
        "    # return score"
      ],
      "metadata": {
        "id": "N8lqVkQWuhuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJRsGjr01xY8",
        "outputId": "1060dd17-f7d9-45ac-a1a2-b594f02f011e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7761, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next steps \n",
        "- Double Check that the loss is reasonable\n",
        "- Disable the regularization (Lambda = 0)"
      ],
      "metadata": {
        "id": "g_QpYhW7vMmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.00001\n",
        "Lambda = 0\n",
        "train_and_test_loop(1, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pg90R6Xumyr",
        "outputId": "4237dc9a-a80b-4ad0-d10d-a7faddf46aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6939 - accuracy: 0.4763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question\n",
        "- Is the loss range correct? What about accuracy, does it make sense for an untrained network\n",
        "\n",
        "### Answer\n",
        "- Absolutely! There are 2 output classes and the model is correctly predicting 1 up on 2 times (1/2 = 0.5% approx) as it is untrained.\n",
        "\n",
        "### Now, lets crank up the Lambda(Regularization)and check what it does to our loss function.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7mpcY6DcvTIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.00001\n",
        "Lambda = 1e3\n",
        "train_and_test_loop(1, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axok-9vSvaXj",
        "outputId": "504a6d7e-a8c0-4e3e-f955-5834254da575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "493/493 [==============================] - 7s 14ms/step - loss: 61.3253 - accuracy: 0.6962\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now, lets overfit to a small subset of our dataset, in this case 20 images, to ensure our model architecture is good\n"
      ],
      "metadata": {
        "id": "gAx8SEsSv4iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_subset = X_train[0:20]\n",
        "\n",
        "y_train_subset = y_train[0:20]"
      ],
      "metadata": {
        "id": "UdLbcoWEv3sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IywPDXyPwJmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tip: Make sure that you can overfit very small portion of the training data\n",
        "\n",
        "\n",
        "So, set a small learning rate and turn regularization off\n",
        "\n",
        "In the code below:\n",
        "- Take the first 20 examples from MNIST\n",
        "- turn off regularization(reg=0.0)\n",
        "- use simple vanilla 'sgd'\n",
        "\n",
        "Lets try and run for 500 iterations as the data set is very small"
      ],
      "metadata": {
        "id": "rQPg86NpwJwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tYnpmdETwI4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "Lambda = 0\n",
        "train_and_test_loop1(500, lr, Lambda)\n",
        "\n",
        "### Very small loss,  train accuracy going to 100, nice! We are successful in overfitting. The model architecture looks fine. Lets go for fine tuning it.\n",
        "\n",
        "### Loading the original dataset again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejxrfBuGvqvs",
        "outputId": "72c391b0-0729-4c81-ba68-7c0193e0e0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 463ms/step - loss: 0.6902 - accuracy: 0.5500\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6901 - accuracy: 0.5500\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6900 - accuracy: 0.6000\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6898 - accuracy: 0.6500\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6896 - accuracy: 0.6500\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6893 - accuracy: 0.6500\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6889 - accuracy: 0.6500\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6885 - accuracy: 0.7000\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6881 - accuracy: 0.7000\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6877 - accuracy: 0.7000\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6872 - accuracy: 0.7000\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6867 - accuracy: 0.7000\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6862 - accuracy: 0.7500\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6857 - accuracy: 0.7000\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6852 - accuracy: 0.7000\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6846 - accuracy: 0.7500\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6840 - accuracy: 0.7000\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6835 - accuracy: 0.7000\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6829 - accuracy: 0.7500\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6823 - accuracy: 0.7500\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6817 - accuracy: 0.6500\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6811 - accuracy: 0.6500\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6805 - accuracy: 0.6000\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6800 - accuracy: 0.6000\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6794 - accuracy: 0.6000\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6788 - accuracy: 0.6000\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6782 - accuracy: 0.6000\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6776 - accuracy: 0.6000\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6771 - accuracy: 0.6000\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6765 - accuracy: 0.6000\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6760 - accuracy: 0.6000\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6754 - accuracy: 0.6000\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6749 - accuracy: 0.6000\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6743 - accuracy: 0.6000\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6738 - accuracy: 0.6000\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6733 - accuracy: 0.6000\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6728 - accuracy: 0.6000\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6722 - accuracy: 0.6000\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6717 - accuracy: 0.6000\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6712 - accuracy: 0.6000\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6707 - accuracy: 0.6000\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6702 - accuracy: 0.6000\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6697 - accuracy: 0.6000\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6692 - accuracy: 0.6000\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6687 - accuracy: 0.6000\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6682 - accuracy: 0.6000\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6678 - accuracy: 0.6000\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6673 - accuracy: 0.6000\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6668 - accuracy: 0.6000\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6663 - accuracy: 0.6000\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6659 - accuracy: 0.6000\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6654 - accuracy: 0.6000\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6650 - accuracy: 0.6000\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6645 - accuracy: 0.6000\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6641 - accuracy: 0.6000\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6636 - accuracy: 0.6000\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6632 - accuracy: 0.6000\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6628 - accuracy: 0.6000\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6623 - accuracy: 0.6000\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6619 - accuracy: 0.6000\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6615 - accuracy: 0.6000\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6611 - accuracy: 0.6000\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6606 - accuracy: 0.6000\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6602 - accuracy: 0.6000\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6598 - accuracy: 0.6000\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6594 - accuracy: 0.6000\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6590 - accuracy: 0.6000\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6586 - accuracy: 0.6000\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6582 - accuracy: 0.6000\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6578 - accuracy: 0.6000\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6574 - accuracy: 0.6000\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6570 - accuracy: 0.6000\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6566 - accuracy: 0.6000\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6562 - accuracy: 0.6000\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6558 - accuracy: 0.6000\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6554 - accuracy: 0.6000\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6550 - accuracy: 0.6000\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6547 - accuracy: 0.6000\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6543 - accuracy: 0.6000\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6539 - accuracy: 0.6000\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6535 - accuracy: 0.6000\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6532 - accuracy: 0.6000\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6528 - accuracy: 0.6000\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6524 - accuracy: 0.6000\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6521 - accuracy: 0.6000\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6517 - accuracy: 0.6000\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6514 - accuracy: 0.6000\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6510 - accuracy: 0.6000\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6507 - accuracy: 0.6000\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6503 - accuracy: 0.6000\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6500 - accuracy: 0.6000\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6496 - accuracy: 0.6000\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6493 - accuracy: 0.6000\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6489 - accuracy: 0.6000\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6486 - accuracy: 0.6000\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6483 - accuracy: 0.6000\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6479 - accuracy: 0.6000\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6476 - accuracy: 0.6000\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6472 - accuracy: 0.6000\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6469 - accuracy: 0.6000\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6466 - accuracy: 0.6000\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6463 - accuracy: 0.6000\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6459 - accuracy: 0.6000\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6456 - accuracy: 0.6000\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6453 - accuracy: 0.6000\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6450 - accuracy: 0.6000\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6446 - accuracy: 0.6000\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6443 - accuracy: 0.6000\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6440 - accuracy: 0.6000\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6437 - accuracy: 0.6000\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6434 - accuracy: 0.6000\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6430 - accuracy: 0.6000\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6427 - accuracy: 0.6000\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6424 - accuracy: 0.6000\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6421 - accuracy: 0.6000\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6418 - accuracy: 0.6000\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6415 - accuracy: 0.6000\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6411 - accuracy: 0.6000\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6408 - accuracy: 0.6000\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6405 - accuracy: 0.6000\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6402 - accuracy: 0.6000\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6399 - accuracy: 0.6000\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.6000\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6393 - accuracy: 0.6000\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6390 - accuracy: 0.6000\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6387 - accuracy: 0.6000\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6384 - accuracy: 0.6000\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6381 - accuracy: 0.6000\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6378 - accuracy: 0.6000\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6375 - accuracy: 0.6000\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6372 - accuracy: 0.6000\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6369 - accuracy: 0.6000\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6365 - accuracy: 0.6000\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6362 - accuracy: 0.6000\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6359 - accuracy: 0.6000\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6356 - accuracy: 0.6000\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6353 - accuracy: 0.6000\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6350 - accuracy: 0.6000\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6347 - accuracy: 0.6000\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6344 - accuracy: 0.6000\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6341 - accuracy: 0.6000\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6338 - accuracy: 0.6000\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6335 - accuracy: 0.6000\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6332 - accuracy: 0.6000\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6329 - accuracy: 0.6000\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6326 - accuracy: 0.6000\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6323 - accuracy: 0.6000\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6320 - accuracy: 0.6000\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6317 - accuracy: 0.6000\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6313 - accuracy: 0.6000\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6310 - accuracy: 0.6000\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6307 - accuracy: 0.6000\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6304 - accuracy: 0.6000\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6301 - accuracy: 0.6000\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6298 - accuracy: 0.6000\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6295 - accuracy: 0.6000\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6292 - accuracy: 0.6000\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6289 - accuracy: 0.6000\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6286 - accuracy: 0.6000\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6283 - accuracy: 0.6000\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6280 - accuracy: 0.6000\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6277 - accuracy: 0.6000\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6274 - accuracy: 0.6000\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6270 - accuracy: 0.6000\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6267 - accuracy: 0.6000\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6264 - accuracy: 0.6000\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6261 - accuracy: 0.6000\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6258 - accuracy: 0.6000\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6255 - accuracy: 0.6000\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6252 - accuracy: 0.6000\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6249 - accuracy: 0.6000\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6246 - accuracy: 0.6000\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6243 - accuracy: 0.6000\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6240 - accuracy: 0.6000\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6236 - accuracy: 0.6000\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6233 - accuracy: 0.6000\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6230 - accuracy: 0.6000\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6227 - accuracy: 0.6000\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6224 - accuracy: 0.6000\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6221 - accuracy: 0.6000\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6218 - accuracy: 0.6000\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6215 - accuracy: 0.6000\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6211 - accuracy: 0.6000\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6208 - accuracy: 0.6000\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6205 - accuracy: 0.6000\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6202 - accuracy: 0.6000\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6199 - accuracy: 0.6000\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6196 - accuracy: 0.6000\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6193 - accuracy: 0.6000\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6189 - accuracy: 0.6000\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6186 - accuracy: 0.6000\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6183 - accuracy: 0.6000\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6180 - accuracy: 0.6000\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6177 - accuracy: 0.6000\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6173 - accuracy: 0.6000\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6170 - accuracy: 0.6000\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6167 - accuracy: 0.6000\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6164 - accuracy: 0.6000\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6161 - accuracy: 0.6000\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6157 - accuracy: 0.6000\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6154 - accuracy: 0.6000\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6151 - accuracy: 0.6000\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6148 - accuracy: 0.6000\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6144 - accuracy: 0.6000\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6141 - accuracy: 0.6000\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6138 - accuracy: 0.6000\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6135 - accuracy: 0.6000\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6131 - accuracy: 0.6000\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6128 - accuracy: 0.6000\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6125 - accuracy: 0.6000\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6121 - accuracy: 0.6000\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6118 - accuracy: 0.6000\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6115 - accuracy: 0.6000\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6111 - accuracy: 0.6000\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6108 - accuracy: 0.6000\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6105 - accuracy: 0.6000\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6101 - accuracy: 0.6000\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6098 - accuracy: 0.6000\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6094 - accuracy: 0.6000\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6091 - accuracy: 0.6000\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6088 - accuracy: 0.6000\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6084 - accuracy: 0.6000\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6081 - accuracy: 0.6000\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6077 - accuracy: 0.6000\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.6074 - accuracy: 0.6000\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6070 - accuracy: 0.6000\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6067 - accuracy: 0.6000\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6064 - accuracy: 0.6000\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6060 - accuracy: 0.6000\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6057 - accuracy: 0.6000\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6053 - accuracy: 0.6000\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6050 - accuracy: 0.6000\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6046 - accuracy: 0.6000\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6043 - accuracy: 0.6000\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6039 - accuracy: 0.6000\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6036 - accuracy: 0.6000\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6032 - accuracy: 0.6000\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6029 - accuracy: 0.6000\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6025 - accuracy: 0.6000\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6021 - accuracy: 0.6000\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6018 - accuracy: 0.6000\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6014 - accuracy: 0.6000\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6011 - accuracy: 0.6000\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6007 - accuracy: 0.6000\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6004 - accuracy: 0.6000\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.6000 - accuracy: 0.6000\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5996 - accuracy: 0.6000\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5993 - accuracy: 0.6000\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5989 - accuracy: 0.6000\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5986 - accuracy: 0.6000\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5982 - accuracy: 0.6000\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5978 - accuracy: 0.6000\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5975 - accuracy: 0.6000\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5971 - accuracy: 0.6000\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5968 - accuracy: 0.6000\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5964 - accuracy: 0.6000\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5960 - accuracy: 0.6000\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5957 - accuracy: 0.6000\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5953 - accuracy: 0.6000\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5949 - accuracy: 0.6000\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5946 - accuracy: 0.6000\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5942 - accuracy: 0.6000\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5938 - accuracy: 0.6000\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5935 - accuracy: 0.6000\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5931 - accuracy: 0.6000\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5927 - accuracy: 0.6000\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5924 - accuracy: 0.6000\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5920 - accuracy: 0.6000\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.6000\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5912 - accuracy: 0.6000\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5909 - accuracy: 0.6000\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5905 - accuracy: 0.6000\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5901 - accuracy: 0.6000\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5897 - accuracy: 0.6000\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5893 - accuracy: 0.6000\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5890 - accuracy: 0.6000\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5886 - accuracy: 0.6000\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5882 - accuracy: 0.6000\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5878 - accuracy: 0.6000\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5874 - accuracy: 0.6000\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5870 - accuracy: 0.6000\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5866 - accuracy: 0.6000\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5863 - accuracy: 0.6000\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5859 - accuracy: 0.6000\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5855 - accuracy: 0.6000\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5851 - accuracy: 0.6000\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5847 - accuracy: 0.6000\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5843 - accuracy: 0.6000\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5839 - accuracy: 0.6000\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5835 - accuracy: 0.6000\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5831 - accuracy: 0.6000\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5827 - accuracy: 0.6000\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5823 - accuracy: 0.6000\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5819 - accuracy: 0.6000\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5815 - accuracy: 0.6000\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5811 - accuracy: 0.6000\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5807 - accuracy: 0.6000\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5803 - accuracy: 0.6000\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5799 - accuracy: 0.6000\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5795 - accuracy: 0.6000\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5791 - accuracy: 0.6000\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5787 - accuracy: 0.6000\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5783 - accuracy: 0.6000\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5779 - accuracy: 0.6000\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5775 - accuracy: 0.6000\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5771 - accuracy: 0.6000\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5766 - accuracy: 0.6000\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5762 - accuracy: 0.6000\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5758 - accuracy: 0.6000\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5754 - accuracy: 0.6000\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5750 - accuracy: 0.6000\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5745 - accuracy: 0.6000\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5741 - accuracy: 0.6000\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5737 - accuracy: 0.6000\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5733 - accuracy: 0.6000\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5728 - accuracy: 0.6000\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5724 - accuracy: 0.6000\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5720 - accuracy: 0.6000\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5715 - accuracy: 0.6000\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5711 - accuracy: 0.6000\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5707 - accuracy: 0.6000\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5702 - accuracy: 0.6000\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5698 - accuracy: 0.6000\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5693 - accuracy: 0.6000\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5689 - accuracy: 0.6000\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5685 - accuracy: 0.6000\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5680 - accuracy: 0.6000\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5676 - accuracy: 0.6000\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5671 - accuracy: 0.6000\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5667 - accuracy: 0.6000\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5662 - accuracy: 0.6000\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5658 - accuracy: 0.6000\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5653 - accuracy: 0.6000\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5649 - accuracy: 0.6000\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5644 - accuracy: 0.6000\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5640 - accuracy: 0.6000\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5635 - accuracy: 0.6000\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5630 - accuracy: 0.6000\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5626 - accuracy: 0.6000\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5621 - accuracy: 0.6000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5617 - accuracy: 0.6000\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5612 - accuracy: 0.6000\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5607 - accuracy: 0.6000\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5603 - accuracy: 0.6000\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5598 - accuracy: 0.6000\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5593 - accuracy: 0.6000\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5589 - accuracy: 0.6000\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5584 - accuracy: 0.6000\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5579 - accuracy: 0.6000\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5574 - accuracy: 0.6000\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5570 - accuracy: 0.6000\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5565 - accuracy: 0.6000\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5560 - accuracy: 0.6000\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5555 - accuracy: 0.6000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5550 - accuracy: 0.6000\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5545 - accuracy: 0.6000\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5541 - accuracy: 0.6000\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5536 - accuracy: 0.6000\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5531 - accuracy: 0.6000\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5526 - accuracy: 0.6000\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5521 - accuracy: 0.6000\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5516 - accuracy: 0.6000\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5511 - accuracy: 0.6000\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5506 - accuracy: 0.6000\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5501 - accuracy: 0.6000\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5496 - accuracy: 0.6000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5491 - accuracy: 0.6000\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5486 - accuracy: 0.6000\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5481 - accuracy: 0.6000\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5476 - accuracy: 0.6000\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5471 - accuracy: 0.6000\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5466 - accuracy: 0.6000\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5461 - accuracy: 0.6000\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5455 - accuracy: 0.6000\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5450 - accuracy: 0.6000\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5445 - accuracy: 0.6000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5440 - accuracy: 0.6000\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5435 - accuracy: 0.6000\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5430 - accuracy: 0.6000\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5424 - accuracy: 0.6000\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5419 - accuracy: 0.6000\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5414 - accuracy: 0.6000\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5409 - accuracy: 0.6000\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5403 - accuracy: 0.6000\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5398 - accuracy: 0.6000\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5393 - accuracy: 0.6000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5387 - accuracy: 0.6000\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5382 - accuracy: 0.6000\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5377 - accuracy: 0.6000\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5371 - accuracy: 0.6000\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5366 - accuracy: 0.6000\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5360 - accuracy: 0.6000\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5355 - accuracy: 0.6000\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5350 - accuracy: 0.6000\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.5344 - accuracy: 0.6000\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5339 - accuracy: 0.6000\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5333 - accuracy: 0.6000\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5328 - accuracy: 0.6000\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5322 - accuracy: 0.6000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5317 - accuracy: 0.6000\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5311 - accuracy: 0.6000\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5305 - accuracy: 0.6000\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5300 - accuracy: 0.6000\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5294 - accuracy: 0.6000\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5289 - accuracy: 0.6000\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5283 - accuracy: 0.6000\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5277 - accuracy: 0.6000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5272 - accuracy: 0.6000\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5266 - accuracy: 0.6000\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5260 - accuracy: 0.6000\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5254 - accuracy: 0.6000\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5249 - accuracy: 0.6500\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5243 - accuracy: 0.6500\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5237 - accuracy: 0.6500\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5231 - accuracy: 0.6500\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5226 - accuracy: 0.6500\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5220 - accuracy: 0.6500\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5214 - accuracy: 0.7000\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5208 - accuracy: 0.7500\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5202 - accuracy: 0.8000\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5196 - accuracy: 0.8000\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5190 - accuracy: 0.8000\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5184 - accuracy: 0.8000\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5178 - accuracy: 0.8000\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.5172 - accuracy: 0.8000\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5166 - accuracy: 0.8000\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5160 - accuracy: 0.8000\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5154 - accuracy: 0.8000\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5148 - accuracy: 0.8000\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5142 - accuracy: 0.8000\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5136 - accuracy: 0.8000\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5130 - accuracy: 0.8000\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5124 - accuracy: 0.8000\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5118 - accuracy: 0.8000\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5112 - accuracy: 0.8000\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5105 - accuracy: 0.8000\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5099 - accuracy: 0.8000\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5093 - accuracy: 0.8000\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5087 - accuracy: 0.8000\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5080 - accuracy: 0.8000\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5074 - accuracy: 0.8000\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5068 - accuracy: 0.8000\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5061 - accuracy: 0.8000\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5055 - accuracy: 0.8000\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5049 - accuracy: 0.8000\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.5043 - accuracy: 0.8000\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5036 - accuracy: 0.8000\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5030 - accuracy: 0.8000\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5023 - accuracy: 0.8000\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5017 - accuracy: 0.8000\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5011 - accuracy: 0.8000\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5004 - accuracy: 0.8000\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4998 - accuracy: 0.8000\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4991 - accuracy: 0.8000\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4985 - accuracy: 0.8000\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4978 - accuracy: 0.8500\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4972 - accuracy: 0.8500\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4965 - accuracy: 0.8500\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4959 - accuracy: 0.8500\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4952 - accuracy: 0.8500\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4946 - accuracy: 0.9000\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4939 - accuracy: 0.9000\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4933 - accuracy: 0.9000\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4926 - accuracy: 0.9000\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4919 - accuracy: 0.9000\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4913 - accuracy: 0.9000\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4906 - accuracy: 0.9000\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4899 - accuracy: 0.9000\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4893 - accuracy: 0.9000\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4886 - accuracy: 0.9000\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4879 - accuracy: 0.9000\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4872 - accuracy: 0.9000\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4866 - accuracy: 0.9000\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4859 - accuracy: 0.9000\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4852 - accuracy: 0.9000\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4845 - accuracy: 0.9000\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4838 - accuracy: 0.9000\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4831 - accuracy: 0.9000\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4825 - accuracy: 0.9000\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4818 - accuracy: 0.9500\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4811 - accuracy: 0.9500\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4804 - accuracy: 0.9500\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4797 - accuracy: 0.9500\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4790 - accuracy: 0.9500\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4783 - accuracy: 0.9500\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4776 - accuracy: 0.9500\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4769 - accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4762 - accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4754 - accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4747 - accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4740 - accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4733 - accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4726 - accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4719 - accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4712 - accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4704 - accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4697 - accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4690 - accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4683 - accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.4675 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Reshape Features if needed\n",
        "## Normalize features if needed\n"
      ],
      "metadata": {
        "id": "iqK7H4t2xEAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-7\n",
        "Lambda = 1e-7\n",
        "train_and_test_loop(20, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyATUf-yxfmq",
        "outputId": "0382c188-9bf3-425d-cd2f-abdd5e42a382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6968 - accuracy: 0.3714\n",
            "Epoch 2/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6967 - accuracy: 0.3744\n",
            "Epoch 3/20\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6967 - accuracy: 0.3760\n",
            "Epoch 4/20\n",
            "493/493 [==============================] - 8s 17ms/step - loss: 0.6966 - accuracy: 0.3779\n",
            "Epoch 5/20\n",
            "493/493 [==============================] - 8s 16ms/step - loss: 0.6965 - accuracy: 0.3805\n",
            "Epoch 6/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6964 - accuracy: 0.3829\n",
            "Epoch 7/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6963 - accuracy: 0.3863\n",
            "Epoch 8/20\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6962 - accuracy: 0.3884\n",
            "Epoch 9/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6961 - accuracy: 0.3911\n",
            "Epoch 10/20\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6961 - accuracy: 0.3934\n",
            "Epoch 11/20\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6960 - accuracy: 0.3959\n",
            "Epoch 12/20\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6959 - accuracy: 0.3989\n",
            "Epoch 13/20\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6958 - accuracy: 0.4022\n",
            "Epoch 14/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6957 - accuracy: 0.4045\n",
            "Epoch 15/20\n",
            "493/493 [==============================] - 8s 16ms/step - loss: 0.6956 - accuracy: 0.4077\n",
            "Epoch 16/20\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6955 - accuracy: 0.4109\n",
            "Epoch 17/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6955 - accuracy: 0.4141\n",
            "Epoch 18/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6954 - accuracy: 0.4176\n",
            "Epoch 19/20\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6953 - accuracy: 0.4203\n",
            "Epoch 20/20\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6952 - accuracy: 0.4239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V06Ctb1uxvua",
        "outputId": "8bd12831-7429-4559-fd80-d58db5240322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2352, 2500, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Loss barely changing. Learning rate is probably too low.\n",
        "\n",
        "### Okay now lets try a (larger) learning rate 1e6. What could possibly go wrong?\n",
        "\n",
        "# - Learning rate lr = 1e8\n",
        "# - Regularization lambda = 1e-7\n",
        "\n",
        "\n",
        "lr = 1e8\n",
        "Lambda = 1e-7\n",
        "train_and_test_loop(10, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XglyXzOnxl9V",
        "outputId": "b662e97a-2f3a-4397-b5cf-50a7f8d3a013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "493/493 [==============================] - 6s 12ms/step - loss: nan - accuracy: 0.7102\n",
            "Epoch 2/10\n",
            "493/493 [==============================] - 6s 12ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 3/10\n",
            "493/493 [==============================] - 6s 13ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 4/10\n",
            "493/493 [==============================] - 6s 12ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 5/10\n",
            "493/493 [==============================] - 6s 12ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 6/10\n",
            "493/493 [==============================] - 6s 12ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 7/10\n",
            "493/493 [==============================] - 6s 13ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 8/10\n",
            "493/493 [==============================] - 6s 12ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 9/10\n",
            "493/493 [==============================] - 6s 13ms/step - loss: nan - accuracy: 0.7105\n",
            "Epoch 10/10\n",
            "493/493 [==============================] - 7s 13ms/step - loss: nan - accuracy: 0.7105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Optimization\n",
        "\n",
        "### Cross validation Strategy\n",
        "\n",
        "\n",
        "- Do coarse -> fine cross-validation in stages\n",
        "\n",
        "- First stage: only a few epochs to get rough idea of what params work\n",
        "- Second stage: longer running time, finer search\n",
        "- … (repeat as necessary)\n",
        "\n",
        "### Tip for detecting explosions in the solver: \n",
        "- If the cost is ever > 3 * original cost, break out early\n"
      ],
      "metadata": {
        "id": "OXNq0G0F6eht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### For example: Run coarse search for 10 times with different lr and Lambda values each with 100 epochs.\n",
        "import math\n",
        "for k in range(1,10):\n",
        "    lr = math.pow(10, np.random.uniform(-5.0, 2.0))\n",
        "    Lambda = math.pow(10, np.random.uniform(-7,-2))\n",
        "    best_acc = train_and_test_loop(30, lr, Lambda, False)\n",
        "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxHOE8Lu6lAY",
        "outputId": "f34276ef-e54e-4d70-d421-97a834c8e960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "493/493 [==============================] - 8s 15ms/step - loss: 0.5867 - accuracy: 0.7156\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 5s 11ms/step - loss: 0.6243 - accuracy: 0.7000\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6173 - accuracy: 0.7063\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6204 - accuracy: 0.7086\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6180 - accuracy: 0.7087\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6204 - accuracy: 0.7054\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6258 - accuracy: 0.7034\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6153 - accuracy: 0.7017\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6162 - accuracy: 0.7073\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6211 - accuracy: 0.7007\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6263 - accuracy: 0.7031\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6235 - accuracy: 0.7006\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6226 - accuracy: 0.7016\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6208 - accuracy: 0.7077\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6259 - accuracy: 0.7001\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 6s 11ms/step - loss: 0.6153 - accuracy: 0.7081\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6170 - accuracy: 0.7091\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 7s 15ms/step - loss: 0.6173 - accuracy: 0.7083\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6161 - accuracy: 0.7105\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6175 - accuracy: 0.7058\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6177 - accuracy: 0.7020\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6196 - accuracy: 0.7071\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6126 - accuracy: 0.7089\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6141 - accuracy: 0.7067\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6160 - accuracy: 0.7076\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6239 - accuracy: 0.7043\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6165 - accuracy: 0.7083\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6257 - accuracy: 0.6979\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6221 - accuracy: 0.7036\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6140 - accuracy: 0.7105\n",
            "Try 1/100: Best_val_acc: None, lr: 0.503723663956603, Lambda: 6.323468123842003e-07\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.5348 - accuracy: 0.7398\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.3667 - accuracy: 0.8392\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.3040 - accuracy: 0.8687\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 7s 15ms/step - loss: 0.2873 - accuracy: 0.8781\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 7s 15ms/step - loss: 0.2514 - accuracy: 0.8962\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2223 - accuracy: 0.9070\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.1799 - accuracy: 0.9276\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.1392 - accuracy: 0.9488\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1022 - accuracy: 0.9632\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0788 - accuracy: 0.9723\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0515 - accuracy: 0.9834\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0580 - accuracy: 0.9781\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0247 - accuracy: 0.9937\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0134 - accuracy: 0.9970\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0053 - accuracy: 0.9996\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0032 - accuracy: 0.9997\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0024 - accuracy: 0.9999\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0023 - accuracy: 0.9999\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0022 - accuracy: 0.9999\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0021 - accuracy: 0.9999\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0021 - accuracy: 0.9999\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0020 - accuracy: 0.9999\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0021 - accuracy: 0.9999\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0019 - accuracy: 0.9999\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0020 - accuracy: 0.9999\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0019 - accuracy: 0.9999\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0018 - accuracy: 0.9999\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0017 - accuracy: 0.9999\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0020 - accuracy: 0.9999\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0018 - accuracy: 0.9999\n",
            "Try 2/100: Best_val_acc: None, lr: 0.02134643619715813, Lambda: 1.4341977661475303e-05\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5011 - accuracy: 0.7667\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.3711 - accuracy: 0.8375\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.3384 - accuracy: 0.8535\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.3130 - accuracy: 0.8692\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.3123 - accuracy: 0.8653\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2730 - accuracy: 0.8860\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2852 - accuracy: 0.8800\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2497 - accuracy: 0.8932\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.2164 - accuracy: 0.9097\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.1945 - accuracy: 0.9182\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.2097 - accuracy: 0.9131\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1849 - accuracy: 0.9249\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1689 - accuracy: 0.9296\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1595 - accuracy: 0.9334\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.1577 - accuracy: 0.9348\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1484 - accuracy: 0.9377\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.1157 - accuracy: 0.9534\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1034 - accuracy: 0.9583\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0911 - accuracy: 0.9639\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0706 - accuracy: 0.9736\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 6s 11ms/step - loss: 0.0658 - accuracy: 0.9756\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0586 - accuracy: 0.9770\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0425 - accuracy: 0.9844\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0412 - accuracy: 0.9846\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0302 - accuracy: 0.9902\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0296 - accuracy: 0.9898\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0336 - accuracy: 0.9877\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0288 - accuracy: 0.9911\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0314 - accuracy: 0.9887\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0248 - accuracy: 0.9909\n",
            "Try 3/100: Best_val_acc: None, lr: 0.18604444701552073, Lambda: 5.10650824156077e-07\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.4852 - accuracy: 0.7732\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.3463 - accuracy: 0.8520\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.3090 - accuracy: 0.8680\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2726 - accuracy: 0.8852\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2580 - accuracy: 0.8886\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.2368 - accuracy: 0.9001\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2087 - accuracy: 0.9136\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.1983 - accuracy: 0.9196\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1693 - accuracy: 0.9327\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1627 - accuracy: 0.9335\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.1578 - accuracy: 0.9372\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 5s 11ms/step - loss: 0.1141 - accuracy: 0.9541\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1156 - accuracy: 0.9539\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0801 - accuracy: 0.9693\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0570 - accuracy: 0.9781\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0584 - accuracy: 0.9777\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0391 - accuracy: 0.9867\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0640 - accuracy: 0.9761\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0391 - accuracy: 0.9870\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0328 - accuracy: 0.9882\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0184 - accuracy: 0.9942\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0139 - accuracy: 0.9957\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0174 - accuracy: 0.9945\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0123 - accuracy: 0.9963\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0201 - accuracy: 0.9924\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0130 - accuracy: 0.9962\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0047 - accuracy: 0.9992\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0027 - accuracy: 0.9999\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0021 - accuracy: 0.9999\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0020 - accuracy: 0.9999\n",
            "Try 4/100: Best_val_acc: None, lr: 0.0635890749818055, Lambda: 3.938339840837533e-05\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.7010 - accuracy: 0.3157\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6911 - accuracy: 0.5776\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6822 - accuracy: 0.7072\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6744 - accuracy: 0.7105\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6673 - accuracy: 0.7105\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6609 - accuracy: 0.7105\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6551 - accuracy: 0.7105\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6499 - accuracy: 0.7105\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6452 - accuracy: 0.7105\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6409 - accuracy: 0.7105\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6371 - accuracy: 0.7105\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6336 - accuracy: 0.7105\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6304 - accuracy: 0.7105\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6275 - accuracy: 0.7105\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6248 - accuracy: 0.7105\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6225 - accuracy: 0.7105\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6203 - accuracy: 0.7105\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6184 - accuracy: 0.7105\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6166 - accuracy: 0.7105\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6150 - accuracy: 0.7105\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6136 - accuracy: 0.7105\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6123 - accuracy: 0.7105\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6111 - accuracy: 0.7105\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.6100 - accuracy: 0.7105\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6091 - accuracy: 0.7105\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6082 - accuracy: 0.7105\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6074 - accuracy: 0.7105\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.6067 - accuracy: 0.7105\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6061 - accuracy: 0.7105\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6055 - accuracy: 0.7105\n",
            "Try 5/100: Best_val_acc: None, lr: 1.1751272288505809e-05, Lambda: 1.071028846405833e-05\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 32.5893 - accuracy: 0.5919\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.3178 - accuracy: 0.5979\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.2622 - accuracy: 0.6017\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.4041 - accuracy: 0.6010\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 1.8494 - accuracy: 0.5883\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.5707 - accuracy: 0.5957\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.5523 - accuracy: 0.5997\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 1.4055 - accuracy: 0.6009\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 1.7420 - accuracy: 0.6022\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 1.4598 - accuracy: 0.5976\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.1608 - accuracy: 0.6126\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.3604 - accuracy: 0.6034\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.6458 - accuracy: 0.5913\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.6615 - accuracy: 0.5935\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.3272 - accuracy: 0.6034\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 2.0315 - accuracy: 0.5879\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 1.4036 - accuracy: 0.5964\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.6091 - accuracy: 0.5915\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.7682 - accuracy: 0.5948\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.0995 - accuracy: 0.6056\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.6497 - accuracy: 0.5832\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.5064 - accuracy: 0.5961\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.3200 - accuracy: 0.6108\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 1.5162 - accuracy: 0.6016\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.4435 - accuracy: 0.6029\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 2.4252 - accuracy: 0.5899\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.2500 - accuracy: 0.5956\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 1.1859 - accuracy: 0.6081\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 1.6137 - accuracy: 0.6050\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 1.4306 - accuracy: 0.6062\n",
            "Try 6/100: Best_val_acc: None, lr: 6.198891060125631, Lambda: 8.863456285867356e-05\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6263 - accuracy: 0.7086\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.6016 - accuracy: 0.7105\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.6004 - accuracy: 0.7105\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5994 - accuracy: 0.7105\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5985 - accuracy: 0.7105\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.5973 - accuracy: 0.7105\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.5962 - accuracy: 0.7105\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.5950 - accuracy: 0.7105\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.5935 - accuracy: 0.7105\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5918 - accuracy: 0.7105\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.5900 - accuracy: 0.7105\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.5879 - accuracy: 0.7105\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5854 - accuracy: 0.7105\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.5825 - accuracy: 0.7105\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.5792 - accuracy: 0.7105\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5753 - accuracy: 0.7105\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.5708 - accuracy: 0.7105\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5656 - accuracy: 0.7105\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 7s 15ms/step - loss: 0.5595 - accuracy: 0.7107\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5523 - accuracy: 0.7109\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5443 - accuracy: 0.7117\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.5351 - accuracy: 0.7146\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5247 - accuracy: 0.7202\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5132 - accuracy: 0.7291\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.5012 - accuracy: 0.7413\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.4881 - accuracy: 0.7544\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.4746 - accuracy: 0.7679\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.4614 - accuracy: 0.7801\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.4487 - accuracy: 0.7893\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.4362 - accuracy: 0.7987\n",
            "Try 7/100: Best_val_acc: None, lr: 0.00042815382077715194, Lambda: 8.498606438179089e-05\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.4872 - accuracy: 0.7711\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.3551 - accuracy: 0.8406\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.3084 - accuracy: 0.8680\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2803 - accuracy: 0.8802\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2528 - accuracy: 0.8908\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2323 - accuracy: 0.9005\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2187 - accuracy: 0.9095\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1998 - accuracy: 0.9159\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1860 - accuracy: 0.9225\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1760 - accuracy: 0.9276\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1481 - accuracy: 0.9404\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.1341 - accuracy: 0.9463\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.1133 - accuracy: 0.9536\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1003 - accuracy: 0.9613\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0800 - accuracy: 0.9685\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0713 - accuracy: 0.9728\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0521 - accuracy: 0.9790\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0627 - accuracy: 0.9759\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0337 - accuracy: 0.9883\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0372 - accuracy: 0.9877\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.0283 - accuracy: 0.9891\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0398 - accuracy: 0.9860\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0135 - accuracy: 0.9952\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0093 - accuracy: 0.9969\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0276 - accuracy: 0.9907\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0026 - accuracy: 0.9997\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0030 - accuracy: 0.9996\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0014 - accuracy: 0.9999\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 8.7646e-04 - accuracy: 0.9999\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 9.0537e-04 - accuracy: 0.9999\n",
            "Try 8/100: Best_val_acc: None, lr: 0.07454789949466874, Lambda: 9.108610281879127e-07\n",
            "\n",
            "Epoch 1/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.4708 - accuracy: 0.7808\n",
            "Epoch 2/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.3523 - accuracy: 0.8461\n",
            "Epoch 3/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.3016 - accuracy: 0.8710\n",
            "Epoch 4/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2950 - accuracy: 0.8751\n",
            "Epoch 5/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2553 - accuracy: 0.8969\n",
            "Epoch 6/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2442 - accuracy: 0.8995\n",
            "Epoch 7/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2270 - accuracy: 0.9045\n",
            "Epoch 8/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.2118 - accuracy: 0.9142\n",
            "Epoch 9/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1922 - accuracy: 0.9215\n",
            "Epoch 10/30\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.1888 - accuracy: 0.9238\n",
            "Epoch 11/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1655 - accuracy: 0.9339\n",
            "Epoch 12/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1555 - accuracy: 0.9375\n",
            "Epoch 13/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1454 - accuracy: 0.9421\n",
            "Epoch 14/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1262 - accuracy: 0.9509\n",
            "Epoch 15/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0970 - accuracy: 0.9643\n",
            "Epoch 16/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0747 - accuracy: 0.9725\n",
            "Epoch 17/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0640 - accuracy: 0.9770\n",
            "Epoch 18/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0535 - accuracy: 0.9813\n",
            "Epoch 19/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0394 - accuracy: 0.9877\n",
            "Epoch 20/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0391 - accuracy: 0.9872\n",
            "Epoch 21/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0152 - accuracy: 0.9964\n",
            "Epoch 22/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0059 - accuracy: 0.9997\n",
            "Epoch 23/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0047 - accuracy: 0.9998\n",
            "Epoch 24/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0037 - accuracy: 0.9999\n",
            "Epoch 25/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0035 - accuracy: 0.9999\n",
            "Epoch 26/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0034 - accuracy: 0.9999\n",
            "Epoch 27/30\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.0032 - accuracy: 0.9999\n",
            "Epoch 28/30\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.0031 - accuracy: 0.9999\n",
            "Epoch 29/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0031 - accuracy: 0.9999\n",
            "Epoch 30/30\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.0029 - accuracy: 0.9999\n",
            "Try 9/100: Best_val_acc: None, lr: 0.09911212989464073, Lambda: 0.00043300403126272815\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### As you can see from above, Case 2, 3 and 7 yields good accuracy. It is better to focus on those values for learning rate and Lambda\n",
        "\n",
        "### Now run finer search\n",
        "\n",
        "import math\n",
        "for k in range(1,5):\n",
        "    lr = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
        "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
        "    best_acc = train_and_test_loop1(100, lr, Lambda, False)\n",
        "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))\n",
        "\n",
        "![alt text](https://)### Running deep with lr=0.02 and Lambda=1e-4\n",
        "\n",
        "lr = 2e-2\n",
        "Lambda = 1e-4\n",
        "train_and_test_loop1(100, lr, Lambda)"
      ],
      "metadata": {
        "id": "eLmenBGG6Y-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "Lambda = 1e-5\n",
        "train_and_test_loop(50, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gphUWp6vCYJV",
        "outputId": "445147cc-f4ed-4da3-c974-51ca7d07e929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "493/493 [==============================] - 8s 16ms/step - loss: 0.6115 - accuracy: 0.7099\n",
            "Epoch 2/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5990 - accuracy: 0.7105\n",
            "Epoch 3/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5965 - accuracy: 0.7105\n",
            "Epoch 4/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5932 - accuracy: 0.7105\n",
            "Epoch 5/50\n",
            "493/493 [==============================] - 7s 15ms/step - loss: 0.5888 - accuracy: 0.7105\n",
            "Epoch 6/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5825 - accuracy: 0.7105\n",
            "Epoch 7/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5736 - accuracy: 0.7105\n",
            "Epoch 8/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.5609 - accuracy: 0.7106\n",
            "Epoch 9/50\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.5430 - accuracy: 0.7113\n",
            "Epoch 10/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.5189 - accuracy: 0.7232\n",
            "Epoch 11/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.4898 - accuracy: 0.7511\n",
            "Epoch 12/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.4592 - accuracy: 0.7803\n",
            "Epoch 13/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.4303 - accuracy: 0.8018\n",
            "Epoch 14/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.4054 - accuracy: 0.8188\n",
            "Epoch 15/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.3852 - accuracy: 0.8271\n",
            "Epoch 16/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.3685 - accuracy: 0.8366\n",
            "Epoch 17/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.3544 - accuracy: 0.8441\n",
            "Epoch 18/50\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.3407 - accuracy: 0.8503\n",
            "Epoch 19/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.3290 - accuracy: 0.8576\n",
            "Epoch 20/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.3188 - accuracy: 0.8639\n",
            "Epoch 21/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.3091 - accuracy: 0.8682\n",
            "Epoch 22/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.3000 - accuracy: 0.8742\n",
            "Epoch 23/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2924 - accuracy: 0.8779\n",
            "Epoch 24/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2851 - accuracy: 0.8805\n",
            "Epoch 25/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2772 - accuracy: 0.8833\n",
            "Epoch 26/50\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.2710 - accuracy: 0.8884\n",
            "Epoch 27/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2640 - accuracy: 0.8915\n",
            "Epoch 28/50\n",
            "493/493 [==============================] - 8s 16ms/step - loss: 0.2587 - accuracy: 0.8950\n",
            "Epoch 29/50\n",
            "493/493 [==============================] - 9s 18ms/step - loss: 0.2540 - accuracy: 0.8967\n",
            "Epoch 30/50\n",
            "493/493 [==============================] - 6s 12ms/step - loss: 0.2483 - accuracy: 0.8995\n",
            "Epoch 31/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2443 - accuracy: 0.9012\n",
            "Epoch 32/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2405 - accuracy: 0.9034\n",
            "Epoch 33/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2361 - accuracy: 0.9030\n",
            "Epoch 34/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.2320 - accuracy: 0.9080\n",
            "Epoch 35/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2291 - accuracy: 0.9065\n",
            "Epoch 36/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2237 - accuracy: 0.9117\n",
            "Epoch 37/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.2198 - accuracy: 0.9119\n",
            "Epoch 38/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.2175 - accuracy: 0.9119\n",
            "Epoch 39/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2149 - accuracy: 0.9158\n",
            "Epoch 40/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.2120 - accuracy: 0.9139\n",
            "Epoch 41/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2084 - accuracy: 0.9176\n",
            "Epoch 42/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.2046 - accuracy: 0.9193\n",
            "Epoch 43/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.2031 - accuracy: 0.9191\n",
            "Epoch 44/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.1992 - accuracy: 0.9217\n",
            "Epoch 45/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1997 - accuracy: 0.9209\n",
            "Epoch 46/50\n",
            "493/493 [==============================] - 7s 13ms/step - loss: 0.1954 - accuracy: 0.9226\n",
            "Epoch 47/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1911 - accuracy: 0.9249\n",
            "Epoch 48/50\n",
            "493/493 [==============================] - 7s 14ms/step - loss: 0.1888 - accuracy: 0.9264\n",
            "Epoch 49/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1850 - accuracy: 0.9271\n",
            "Epoch 50/50\n",
            "493/493 [==============================] - 6s 13ms/step - loss: 0.1857 - accuracy: 0.9266\n",
            "493/493 [==============================] - 3s 5ms/step - loss: 0.1735 - accuracy: 0.9331\n",
            "243/243 [==============================] - 1s 5ms/step - loss: 0.3373 - accuracy: 0.8718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.17345312237739563, 0.9331005811691284],\n",
              " [0.33729493618011475, 0.8717948794364929])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "mQxmdP9SGfex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC0HBYUiDx3a",
        "outputId": "95217934-130b-416c-c174-c26e66ee2acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23516, 1500) (23516, 2) (15755, 1500) (15755, 2) (7761, 1500) (7761, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN, LSTM, Bidirectional\n",
        "\n",
        "def RNN_train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "    hidden_nodes = 512\n",
        "    output_nodes = 2\n",
        "\n",
        "    model=Sequential()\n",
        "    model.add(SimpleRNN(50, input_shape=(1500,1), return_sequences=False))\n",
        "    # model.add(SimpleRNN(50, input_shape=(2500,1), return_sequences=False))\n",
        "    model.add(Dense(hidden_nodes, activation='relu'))\n",
        "    model.add(Dense(hidden_nodes, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.l2(Lambda)))\n",
        "    adam=optimizers.Adam(learning_rate=learning_rate)\n",
        "    # sgd = optimizers.SGD(learning_rate=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    model.fit(X, y,  validation_split=0.33, epochs=iterations, batch_size=32, verbose= 1)\n",
        "    # score_train=model.evaluate(X_train,y_train)\n",
        "    # score_eval=model.evaluate(X_test,y_test)\n",
        "\n",
        "    # return score_train,score_eval\n",
        "    "
      ],
      "metadata": {
        "id": "5q8DdnApee4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterations=3\n",
        "lr=1e-6\n",
        "Lambda=0\n",
        "RNN_train_and_test_loop(iterations, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq5116YXrDH7",
        "outputId": "1b95dd50-aa61-4e49-e271-9a3db436802e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "330/330 [==============================] - 149s 450ms/step - loss: 0.6805 - accuracy: 0.6949 - val_loss: 0.6681 - val_accuracy: 0.7038\n",
            "Epoch 2/3\n",
            "330/330 [==============================] - 147s 446ms/step - loss: 0.6537 - accuracy: 0.7138 - val_loss: 0.6441 - val_accuracy: 0.7038\n",
            "Epoch 3/3\n",
            "330/330 [==============================] - 151s 458ms/step - loss: 0.6308 - accuracy: 0.7138 - val_loss: 0.6261 - val_accuracy: 0.7038\n",
            "493/493 [==============================] - 59s 119ms/step - loss: 0.6231 - accuracy: 0.7105\n",
            "243/243 [==============================] - 28s 117ms/step - loss: 0.6239 - accuracy: 0.7087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.6230782866477966, 0.7105045914649963],\n",
              " [0.6238794326782227, 0.7086715698242188])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations=2\n",
        "lr=1e6\n",
        "Lambda=1e-5\n",
        "RNN_train_and_test_loop(iterations, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyuY9fvHMeTR",
        "outputId": "0ec27076-7a06-47a2-dcf0-6525c5a49729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "493/493 [==============================] - 233s 468ms/step - loss: 2775936619617974222848.0000 - accuracy: 0.5043 - val_loss: 24724474167296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "493/493 [==============================] - 228s 462ms/step - loss: 43259179040768.0000 - accuracy: 0.5120 - val_loss: 66231373660160.0000 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations=5\n",
        "lr=1e-6\n",
        "Lambda=1e-5\n",
        "RNN_train_and_test_loop(iterations, lr, Lambda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGIuT8nxPCmr",
        "outputId": "ff4c1087-ad28-49b6-fc9e-3d69729aafd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "493/493 [==============================] - 497s 1s/step - loss: 0.6908 - accuracy: 0.5597 - val_loss: 0.6697 - val_accuracy: 0.9942\n",
            "Epoch 2/5\n",
            "493/493 [==============================] - 479s 971ms/step - loss: 0.6885 - accuracy: 0.5666 - val_loss: 0.6453 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "493/493 [==============================] - 475s 963ms/step - loss: 0.6850 - accuracy: 0.5670 - val_loss: 0.6194 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "493/493 [==============================] - 486s 987ms/step - loss: 0.6829 - accuracy: 0.5670 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "493/493 [==============================] - 487s 989ms/step - loss: 0.6815 - accuracy: 0.5670 - val_loss: 0.5909 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM, GRU, CuDNNLSTM, CuDNNGRU"
      ],
      "metadata": {
        "id": "tGu0aXNPTcyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GRU, LSTM, CuDNNGRU, CuDNNLSTM, Activation\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "w6gLLm8nTKn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "    LSTM_Units = 100\n",
        "    output_nodes = 2\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(LSTM_Units, input_shape = (2500,1), return_sequences = True))\n",
        "    model.add(LSTM(output_nodes, return_sequences = False))\n",
        "    model.add(Activation('sigmoid',kernel_regularizer=regularizers.l2(Lambda)))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    adam=optimizers.Adam(learning_rate=learning_rate)\n",
        "    # sgd = optimizers.SGD(learning_rate=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    model.fit(X, y,  validation_split=0.33, epochs=iterations, batch_size=32, verbose= 1)\n"
      ],
      "metadata": {
        "id": "lJLMIln0Tliy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SQDr8QHcUg5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zXAWlmMxUgOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GRU_train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "    GRU_Units = 100\n",
        "    output_nodes = 2\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(GRU(GRU_Units, input_shape = (2500,1), return_sequences = True))\n",
        "    model.add(GRU(output_nodes, return_sequences = False))\n",
        "    model.add(Activation('sigmoid',kernel_regularizer=regularizers.l2(Lambda)))\n",
        "\n",
        "    adam=optimizers.Adam(learning_rate=learning_rate)\n",
        "    # sgd = optimizers.SGD(learning_rate=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    model.fit(X, y,  validation_split=0.33, epochs=iterations, batch_size=32, verbose= 1)\n"
      ],
      "metadata": {
        "id": "01m0jPK0Ue8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q6eab4ShVAeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EJujDHQIU_kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CuDNNLSTM_train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "    LSTM_Units = 100\n",
        "    output_nodes = 2\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(CuDNNLSTM(LSTM_Units, input_shape = (300,1), return_sequences = True))\n",
        "    model.add(CuDNNLSTM(output_nodes, return_sequences = False))\n",
        "    model.add(Activation('sigmoid',kernel_regularizer=regularizers.l2(Lambda)))\n",
        "\n",
        "    adam=optimizers.Adam(learning_rate=learning_rate)\n",
        "    # sgd = optimizers.SGD(learning_rate=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    model.fit(X, y,  validation_split=0.33, epochs=iterations, batch_size=32, verbose= 1)\n"
      ],
      "metadata": {
        "id": "skDDM3NbU_NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gL3mDTyMVT8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qC3Mkc-IVTkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CuDNNGRU_train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
        "\n",
        "    ## hyperparameters\n",
        "    iterations = iterations\n",
        "    learning_rate = lr\n",
        "    GRU_Units = 100\n",
        "    output_nodes = 2\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(CuDNNGRU(GRU_Units, input_shape = (2500,1), return_sequences = True))\n",
        "    model.add(CuDNNGRU(output_nodes, return_sequences = False))\n",
        "    model.add(Activation('sigmoid',kernel_regularizer=regularizers.l2(Lambda)))\n",
        "\n",
        "    adam=optimizers.Adam(learning_rate=learning_rate)\n",
        "    # sgd = optimizers.SGD(learning_rate=learning_rate, decay=1e-6, momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    model.fit(X, y,  validation_split=0.33, epochs=iterations, batch_size=32, verbose= 1)\n"
      ],
      "metadata": {
        "id": "jCY-9QXYVTRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}